\section*{Limitations}
We acknowledge some limitations despite the promising results of our research that could pave the way for future studies:

1) Our experiments were limited to general NLP tasks and one domain-specific task, more performance assessment on specialized tasks remains to be included.
2) Our method relies on labeled task data for prompt generation and evaluation, raising concerns about its robustness in personalized or scenarios lacking labeled data.
3) Our experiments were confined to GPT-3.5-Turbo, Baichuan2-Turbo and GPT-4, leaving the effectiveness of our method on other large language models to be validated in future studies.

Further study may be needed to address these limitations so as to improve the generalizability and robustness of our approach in broader and more complex real-world applications.